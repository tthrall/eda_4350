{
  "hash": "7ff066d94381f05ee4c0a689edaf1339",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Text Analysis\"\nsubtitle: \"Part 1, session 2b of Data Mining Intro\"\nauthor: \n  - name: \"Send comments to: Tony T (adthral)\"\ndate: \"2025-01-11 02:30 GMT\"\noutput: \n  html_document:\n    toc: true\n    df_print: paged\n    mathjax: default\n  word_document:\n    toc: true\n    df_print: tibble\n  pdf_document:\n    toc: true\n    df_print: tibble\nabstract: \n  \"Introduce basic ideas and methods of text analysis.\"\n---\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n------------------------------------------------------------------------\n\n## Introduction\n\nThis session highlights some basic ideas and methods that underpin a rapidly advancing field. We follow the online book by Silge and Robinson cited below and use their R package `tidytext`. The authors emphasize the \"tidy\" formatting of data (i.e., as key-value pairs) along with a set of R packages sharing this approach, collectively called the R `tidyverse`.\n\n## Text Example\n\nToward the end of Shakespeare's play \"Macbeth\", the protagonist proclaims:\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Life's but a walking shadow, a poor player \"    \n[2] \"That struts and frets his hour upon the stage, \"\n[3] \"And then is heard no more: it is a tale \"       \n[4] \"Told by an idiot, full of sound and fury, \"     \n[5] \"Signifying nothing.\"                            \n```\n\n\n:::\n:::\n\n\n\n(Source: \"Macbeth\", Act V, Scene V, lines 24-28.)\n\nFor purposes of technical analysis we break these flowing lines into a table of words. We begin as follows.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsf_line_tbl <- tibble::tibble(\n  l_idx = 24:28, \n  line  = sound_fury\n)\nsf_line_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 2\n  l_idx line                                             \n  <int> <chr>                                            \n1    24 \"Life's but a walking shadow, a poor player \"    \n2    25 \"That struts and frets his hour upon the stage, \"\n3    26 \"And then is heard no more: it is a tale \"       \n4    27 \"Told by an idiot, full of sound and fury, \"     \n5    28 \"Signifying nothing.\"                            \n```\n\n\n:::\n:::\n\n\n\nThe table above merely identifies the original line number of each line. The next step is to break each line into a sequence of \"tokens\", where a *token* is a meaningful unit of text (such as a word) to be used as the unit of analysis. (\"Tokenization\" is the process of splitting text into tokens.) Applying `tidytext::unnest_tokens()` to the data table above, we obtain the following table, with just one token (word) per row.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsf_token_tbl <- sf_line_tbl |> \n  tidytext::unnest_tokens(\n    input  = \"line\", \n    output = \"word\"\n  )\nsf_token_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 38 × 2\n   l_idx word   \n   <int> <chr>  \n 1    24 life's \n 2    24 but    \n 3    24 a      \n 4    24 walking\n 5    24 shadow \n 6    24 a      \n 7    24 poor   \n 8    24 player \n 9    25 that   \n10    25 struts \n# ℹ 28 more rows\n```\n\n\n:::\n:::\n\n\n\nThe next step is to remove so-called stop-words, that is, articles (\"a\", \"the\", ...), connectors (\"and\", \"or\", ...) and other words that provide structure to a sentence but otherwise carry little information. The `tidytext` package contains a data frame, `stop_words`, of such words, which enables us to remove them from the above table of tokens.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsf_tokens_xsw <- sf_token_tbl |> \n  anti_join(\n    y  = tidytext::stop_words, \n    by = \"word\"\n  )\nsf_tokens_xsw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 16 × 2\n   l_idx word      \n   <int> <chr>     \n 1    24 life's    \n 2    24 walking   \n 3    24 shadow    \n 4    24 poor      \n 5    24 player    \n 6    25 struts    \n 7    25 frets     \n 8    25 hour      \n 9    25 stage     \n10    26 heard     \n11    26 tale      \n12    27 told      \n13    27 idiot     \n14    27 sound     \n15    27 fury      \n16    28 signifying\n```\n\n\n:::\n:::\n\n\n\n## Larger Text Examples\n\nWe'll use larger bodies of text via the following R packages.\n\n### Jane Austen's novels\n\n-   Package `janeaustenr`: Jane Austen (1775-1817) completed 6 novels, which the function `austen_books()` returns as a data frame with 2 columns: the `text` of the novels divided into strings (each approximating a line of printed text), and `book`, which gives the titles of the novels (in order of publication) as a factor.\n\nHere are the number of strings per book.\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  book                n_strings\n  <fct>                   <int>\n1 Sense & Sensibility     12624\n2 Pride & Prejudice       13030\n3 Mansfield Park          15349\n4 Emma                    16235\n5 Northanger Abbey         7856\n6 Persuasion               8328\n```\n\n\n:::\n:::\n\n\n\nHere are the ten words used most frequently across these novels (excluding stop-words).\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Jane Austen: 10 most common (non-stop) words\n\n|word   | count|\n|:------|-----:|\n|miss   |  1855|\n|time   |  1337|\n|fanny  |   862|\n|dear   |   822|\n|lady   |   817|\n|sir    |   806|\n|day    |   797|\n|emma   |   787|\n|sister |   727|\n|house  |   699|\n\n\n:::\n:::\n\n\n\n### The Gutenberg Project\n\n-   Package `gutenbergr`: Enables the user to download and process public domain works in the [Project Gutenberg](https://www.gutenberg.org/) collection.\n\nThe collection boasts over 75000 free electronic books. The data frame `gutenberg_subjects` uses the Library of Congress Classifications (`lcc`) and Library of Congress Subject Headings (`lcsh`) to categorize topics included in the collection. The package offers this and other such metadata to facilitate searching for desired works.\n\nAs a contrast with Jane Austen, here are some well-known science fiction novels of H.G. Wells (1866-1946).\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 2\n     id title                      \n  <int> <chr>                      \n1    35 The Time Machine           \n2    36 The War of the Worlds      \n3  5230 The Invisible Man          \n4   159 The Island of Doctor Moreau\n```\n\n\n:::\n:::\n\n\n\nAmong these novels, here are the most frequently used words (again excluding stop-words).\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: H.G. Wells: 10 most common (non-stop) words\n\n|word   | count|\n|:------|-----:|\n|time   |   454|\n|people |   302|\n|door   |   260|\n|heard  |   249|\n|black  |   232|\n|stood  |   229|\n|white  |   222|\n|hand   |   218|\n|kemp   |   213|\n|eyes   |   210|\n\n\n:::\n:::\n\n\n\n## Class Exercise\n\nTeam up with a classmate and devise a way to compare word frequencies in the novels of Jane Austen and H.G. Wells, respectively. Share with the class your comparison of just the top 10 words used by each author. Propose a method for comparing all the words used by each author. Take 20 minutes to prepare to report to the class.\n\n## TF-IDF: Term Frequency - Inverse Doc Frequency\n\nCan the number of times each word appears in a document be used to indicate what the document is about? On the one hand, the number of occurrences of a given word in a given document might indicate the importance of the word within the document. On the other hand, words that commonly occur in most documents are unlikely to distinguish the key ideas in a given document.\n\nWe've already introduced one way to separate the wheat from the chaff: remove stop-words. Another approach, called *tf-idf*, is to multiply a term's relative frequency (tf) in a selected document by its *inverse document frequency* (idf) with respect to a collection or *corpus* of documents. That is, the relative frequency of a term $t_0$ in a given document $d_0$ is the number of occurrences $\\mathcal{n}(t_0, d_0)$ of the given term divided by the number of occurrences of all terms.\n\n$$\n\\begin{align}\n  tf(t_0, d_0) &= \\frac{\\mathcal{n}(t_0, d_0)}{\\sum_{t \\in d_0}\\mathcal{n}(t, d_0)}\n\\end{align}\n$$\n\nAs for inverse document frequency (idf), there are several alternative definitions. Here's the definition we'll use.\n\n$$\n\\begin{align}\n  idf(t, \\mathcal{D}) &= \\log_e \\left( \\frac{| \\mathcal{D} |}{| \\mathcal{D}_t |} \\right) \\\\ \n  \\\\ \n  & t = \\text{term} \\\\ \n  & \\mathcal{D} = \\text{corpus of documents } \\\\\n  & \\mathcal{D}_t = \\{ d \\in \\mathcal{D} : t \\in d  \\}\n\\end{align}\n$$\n\nExample: let $\\mathcal{D}$ denote the set of Jane Austen's 6 novels, and let each novel take its turn as the document $d_0$ of interest. For each book, the most distinctive word (that maximizes tf-idf) is as follows.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Max tf-idf word per book\n\n|book                |word     |   n|    tf|   idf| tf_idf|\n|:-------------------|:--------|---:|-----:|-----:|------:|\n|Sense & Sensibility |elinor   | 623| 0.005| 1.792|  0.009|\n|Pride & Prejudice   |darcy    | 373| 0.003| 1.792|  0.005|\n|Mansfield Park      |crawford | 493| 0.003| 1.792|  0.006|\n|Emma                |emma     | 786| 0.005| 1.099|  0.005|\n|Northanger Abbey    |tilney   | 196| 0.003| 1.792|  0.005|\n|Persuasion          |elliot   | 254| 0.003| 1.792|  0.005|\n\n\n:::\n:::\n\n\n\n## Document-Term Matrix (DTM)\n\nSo far, we've been analyzing text arranged in the tidy text format: a table in which each row pertains to a unique (document, token) pair. The `tidytext::unnest_tokens()` function counts the number of occurrences of each such pair. Tables in this format can be explored and visualized using the suite of tidy tools, including packages `dplyr`, `tidyr`, and `ggplot2`.\n\nAside from the `tidytext` package, most R tools for natural language processing aren't compatible with this format. The [CRAN Task View for Natural Language Processing](https://cran.r-project.org/web/views/NaturalLanguageProcessing.html) lists packages that take other structures of input and provide non-tidy outputs. These packages are very useful in text mining applications, and many existing text datasets are structured according to these non-tidy formats.\n\nOne of the most common structures that text mining packages work with is the [document-term matrix](https://en.wikipedia.org/wiki/Document-term_matrix) (or DTM). This is a matrix where:\n\n-   each row represents one document (such as a book or article),\n-   each column represents one term, and\n-   each value (typically) contains the number of appearances of that term in that document.\n\nSince most (document, term) pairings have zero occurrences, DTMs are usually implemented as sparse matrices. These objects can be treated as matrices (enabling one to access particular rows and columns), but are stored in a more efficient format.\n\nDTM objects cannot be used directly with tidy tools, and tidy data frames cannot be used as input for most text mining packages. Therefore, the `tidytext` package provides two functions that convert between the two formats.\n\n-   `tidy()` turns a document-term matrix into a tidy data frame. This function comes from the `broom` package, which provides similar tidying functions for many statistical models and objects.\n-   `cast()` turns a tidy one-term-per-row data frame into a matrix. Package `tidytext` provides three variations of this function, each converting to a different type of matrix:\n    -   `cast_sparse()` (converting to a sparse matrix from the `Matrix` package);\n    -   `cast_dtm()` (converting to a `DocumentTermMatrix` object from package `tm`); and\n    -   `cast_dfm()` (converting to a `dfm` object from quanteda).\n\nA widely used implementation of DTMs in R is the `DocumentTermMatrix` class in the `tm` package. Many available text mining datasets are provided in this format.\n\n### Example: Associated Press articles\n\nAs an example, here's a description of Associated Press newspaper articles included as a DTM in the `topicmodels` package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (topicmodels_loaded) {\n  data(\"AssociatedPress\", package = \"topicmodels\")\n}\n\n# AssociatedPress\n# <<DocumentTermMatrix (documents: 2246, terms: 10473)>>\n# Non-/sparse entries: 302031/23220327\n# Sparsity           : 99%\n# Maximal term length: 18\n# Weighting          : term frequency (tf)\n```\n:::\n\n\n\nThis Associated Press DTM consists of 2246 documents (rows) and 10473 terms (columns), with 99% of the potential (document, term) pairings having zero instances (and thus excluded from the sparse matrix).\n\n### Example: inaugural addresses of US presidents\n\nThe inaugural addresses of US presidents, provided by package `quanteda`, is an interesting example of a document-features matrix (DFM), a variant of a DTM. Here are the identifying variables for the first 6 presidential addresses.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"data_corpus_inaugural\", package = \"quanteda\")\nhead(docvars(data_corpus_inaugural), 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Year  President FirstName                 Party\n1 1789 Washington    George                  none\n2 1793 Washington    George                  none\n3 1797      Adams      John            Federalist\n4 1801  Jefferson    Thomas Democratic-Republican\n5 1805  Jefferson    Thomas Democratic-Republican\n6 1809    Madison     James Democratic-Republican\n```\n\n\n:::\n:::\n\n\n\nHere is a list of tokens from the addresses given in 1861, 1933, and 1961.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsome_presidential_tokens <- data_corpus_inaugural |> \n  corpus_subset(Year %in% c(1861L, 1933L, 1961L)) |> \n  tokens()\nsome_presidential_tokens\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTokens consisting of 3 documents and 4 docvars.\n1861-Lincoln :\n [1] \"Fellow-Citizens\" \"of\"              \"the\"             \"United\"         \n [5] \"States\"          \":\"               \"In\"              \"compliance\"     \n [9] \"with\"            \"a\"               \"custom\"          \"as\"             \n[ ... and 3,987 more ]\n\n1933-Roosevelt :\n [1] \"I\"         \"am\"        \"certain\"   \"that\"      \"my\"        \"fellow\"   \n [7] \"Americans\" \"expect\"    \"that\"      \"on\"        \"my\"        \"induction\"\n[ ... and 2,045 more ]\n\n1961-Kennedy :\n [1] \"Vice\"      \"President\" \"Johnson\"   \",\"         \"Mr\"        \".\"        \n [7] \"Speaker\"   \",\"         \"Mr\"        \".\"         \"Chief\"     \"Justice\"  \n[ ... and 1,529 more ]\n```\n\n\n:::\n:::\n\n\n\nHere is a rendering of this list of tokens as a document-feature matrix (DFM).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npresidential_dfm <- some_presidential_tokens |> \n  quanteda::dfm()\npresidential_dfm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDocument-feature matrix of: 3 documents, 1,746 features (56.62% sparse) and 4 docvars.\n                features\ndocs             fellow-citizens  of the united states : in compliance with  a\n  1861-Lincoln                 1 146 256      5     19 5 77          1   20 56\n  1933-Roosevelt               0 109 130      2      3 0 44          0   13 38\n  1961-Kennedy                 0  65  86      2      2 4 26          0    5 29\n[ reached max_nfeat ... 1,736 more features ]\n```\n\n\n:::\n:::\n\n\n\nWe now reconfigure the DFM as a tidy data frame (tibble).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npresidential_tbl <- presidential_dfm |> \n  tidytext::tidy()\npresidential_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,272 × 3\n   document       term            count\n   <chr>          <chr>           <dbl>\n 1 1861-Lincoln   fellow-citizens     1\n 2 1861-Lincoln   of                146\n 3 1933-Roosevelt of                109\n 4 1961-Kennedy   of                 65\n 5 1861-Lincoln   the               256\n 6 1933-Roosevelt the               130\n 7 1961-Kennedy   the                86\n 8 1861-Lincoln   united              5\n 9 1933-Roosevelt united              2\n10 1961-Kennedy   united              2\n# ℹ 2,262 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\nWe can now use `tidytext::bind_tf_idf()` to determine the words that most distinguish the three presidential addresses.\n\n## Topic Models\n\nText analysis methods can be applied to a variety of document types, including books, speeches, blog posts, news articles, and so on. Sometimes we can divide a collection of documents into natural groups to be analyzed separately. We can also use topic modeling to construct such groups. Topic modeling is the unsupervised categorization of documents, similar to clustering of numeric data.\n\n### Latent Dirichlet allocation (LDA)\n\nLatent Dirichlet allocation (LDA) is a popular method for fitting topic models, and is guided by two principles.\n\n-   **Every document is a mixture of topics.** For example, in a two-topic model we could say \"Document 1 is 90% topic A and 10% topic B, while Document 2 is 30% topic A and 70% topic B.\"\n-   **Every topic is a mixture of words.** For example, consider a two-topic model of American news, with one topic for \"politics\" and one for \"entertainment.\" The most common words in the politics topic might be \"President\", \"Congress\", and \"government\", while the entertainment topic may be made up of words such as \"movies\", \"television\", and \"actor\". Importantly, words can be shared between topics; a word like \"budget\" might appear in both equally.\n\nThis approach allows the constructed groups to overlap, similar to the soft clustering of numeric data.\n\n### Example: Associated Press articles\n\nTo illustrate, we'll apply function `LDA()` to the data set (DTM) `AssociatedPress`, both provided by the `topicmodels` package. The DTM is a collection of 2246 news articles from an American news agency, mostly published around 1988. For purposes of illustration we'll specify a two-topic model, as follows.[^1]\n\n[^1]: Function `LDA()` in package `topicmodels` returns a topic model of class \"LDA_VEM\".  LDA denotes latent Dirichlet allocation.  VEM denotes the Variational Expectation Maximization (EM) algorithm.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (topicmodels_loaded) {\n  ap_lda <- AssociatedPress |> \n    LDA(\n      k = 2, \n      # set a seed so that the output of the model is predictable\n      control = list(seed = 1234)\n    )\n  ap_lda\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nA LDA_VEM topic model with 2 topics.\n```\n\n\n:::\n:::\n\n\n\nWe now construct (topic, term) probabilities (called $\\beta$ in the LDA literature).\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20,946 × 3\n   topic term           beta\n   <int> <chr>         <dbl>\n 1     1 aaron      1.69e-12\n 2     2 aaron      3.90e- 5\n 3     1 abandon    2.65e- 5\n 4     2 abandon    3.99e- 5\n 5     1 abandoned  1.39e- 4\n 6     2 abandoned  5.88e- 5\n 7     1 abandoning 2.45e-33\n 8     2 abandoning 2.34e- 5\n 9     1 abbott     2.13e- 6\n10     2 abbott     2.97e- 5\n# ℹ 20,936 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\nHere are the most probable terms for each of the two constructed topics, along with their probabilities (beta), shown as a bar chart.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](s_2b_4350_files/figure-html/g_ap_top_terms-1.png){width=672}\n:::\n:::\n\n\n\nTopics 1 and 2 seem to pertain to business and politics, respectively, although \"new\" and \"people\" are prominent terms for both topics.\n\nAnother way to compare topics 1 and 2 is to examine the terms shared by the two topics and then find the terms having the biggest disparity in (topic, term) probability (beta). Here's a bar chart showing the more prominent differences, expressed as\n\n$$\n\\begin{align}\n  \\log_2 \\left( \\frac{\\beta_2}{\\beta_1} \\right)\n\\end{align}\n$$\n\nrestricting the set of terms to those assigned to both topics $(\\min(\\beta_1, \\beta_2) > 0)$ with at least one of them exceeding a probability threshhold, say $(\\max(\\beta_1, \\beta_2) > 0.001)$.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](s_2b_4350_files/figure-html/g_beta_ratio_wide-1.png){width=672}\n:::\n:::\n\n\n\nThis figure further supports the earlier conjecture that topics 1 and 2 pertain to business and politics, respectively.\n\n## Additional Aspects of Text Analysis\n\nWe've only touched on a few basic ideas and methods underpinning text analysis. Additional topics (on both the analysis and generation of text) include the following (which vary in complexity).\n\n-   n-grams: phrases of $n$ consecutive words\n-   word networks (as graphs)\n-   sentiment analysis\n-   clustering, categorization, and prediction\n-   word embedding (as real-valued vectors)\n-   specialized tokenizers, stemming\n-   non-English human languages (including machine translation)\n-   large language models (LLMs)\n\n## Team Exercises\n\n1.  As a follow-up to the class exercise, propose a way to compare the vocabularies of Austen and Wells. What words are shared most? Least? Should stop-words be excluded? Express your proposal as pseudo-code.\n\n2.  We presented a table showing the word whose tf-idf is maximum for each of Jane Austen's novels. Extend this comparison to show the words having the topmost tf-idf values. How would you present this comparison as a table? As a figure?\n\n3.  Following the example of a document-feature matrix (DFM), extract the inaugural addresses of 1861, 1933, and 1961 from `quanteda::data_corpus_inaugural`. For each token in each address, calculate its tf-idf to determine the tokens that most distinguish the three addresses.\n\n4.  In the preceding exercise, the meta-data give us the name of the speaker and the year of the address. How would you use that knowledge to evaluate a topic-modeling algorithm applied to the inaugural addresses? Time permitting, conduct such an evaluation of a topic-modeling method based on the `topicmodels` R package.\n\n## Resources\n\n[Text Mining with R: A Tidy Approach](https://www.tidytextmining.com/) by Silge and Robinson\n\n[tf–idf - Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n\n[CRAN Task View for Natural Language Processing](https://cran.r-project.org/web/views/NaturalLanguageProcessing.html)\n\n[Introduction to the tm Package: Text Mining in R](https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf)\n\n[Quantitative Analysis of Textual Data • quanteda](https://quanteda.io/)\n\n[Latent Dirichlet Allocation](https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf) by David Blei, Andrew Ng, and Michael Jordan. JMLR (2003)\n",
    "supporting": [
      "s_2b_4350_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}