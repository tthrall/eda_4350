{"title":"Text Analysis","markdown":{"yaml":{"title":"Text Analysis","subtitle":"Part 1, session 2b of Data Mining Intro","author":[{"name":"Send comments to: Tony T (adthral)"}],"date":"`r format(Sys.time(), '%Y-%m-%d %H:%M', usetz = TRUE)`","output":{"html_document":{"toc":true,"df_print":"paged","mathjax":"default"},"word_document":{"toc":true,"df_print":"tibble"},"pdf_document":{"toc":true,"df_print":"tibble"}},"abstract":"Introduce basic ideas and methods of text analysis."},"headingText":"source(here(\"code\", \"rmse_per_grp.R\"))","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  echo    = FALSE, \n  error   = FALSE, \n  message = FALSE, \n  warning = FALSE\n)\n```\n\n```{r libraries}\nlibrary(assertthat)\nlibrary(GGally)\nlibrary(gutenbergr)\nlibrary(here)\nlibrary(ISLR2)\nlibrary(janeaustenr)\nlibrary(latex2exp)\nlibrary(tidytext)\nlibrary(tidyverse)\nlibrary(tinytex)\nlibrary(tokenizers)\nlibrary(topicmodels)\nlibrary(tufte)\n\n```\n\n```{r local_source}\n# source(here(\"code\", \"xtabs_to_jaccard.R\"))\n```\n\n------------------------------------------------------------------------\n\n## Introduction\n\nThis session highlights some basic ideas and methods that underpin a rapidly advancing field.  We follow the online book by Silge and Robinson cited below and use their R package `tidytext`.  The authors emphasize the \"tidy\" formatting of data (i.e., as key-value pairs) along with a set of R packages sharing this approach, collectively called the R `tidyverse`.\n\n## Text Example\n\nToward the end of Shakespeare's play \"Macbeth\", the protagonist proclaims:\n\n```{r sound_fury}\nsound_fury <- c(\"Life's but a walking shadow, a poor player \",\n          \"That struts and frets his hour upon the stage, \",\n          \"And then is heard no more: it is a tale \", \n          \"Told by an idiot, full of sound and fury, \", \n          \"Signifying nothing.\")\n\nsound_fury\n```\n\n(Source: \"Macbeth\", Act V, Scene V, lines 24-28.)\n\nFor purposes of technical analysis we break these flowing lines into a table of words.  We begin as follows.\n\n```{r sf_line_tbl, echo=TRUE}\nsf_line_tbl <- tibble::tibble(\n  l_idx = 24:28, \n  line  = sound_fury\n)\nsf_line_tbl\n```\n\nThe table above merely identifies the original line number of each line.  The next step is to break each line into a sequence of \"tokens\", where a _token_ is a meaningful unit of text (such as a word) to be used as the unit of analysis.  (\"Tokenization\" is the process of splitting text into tokens.)  Applying `tidytext::unnest_tokens()` to the data table above, we obtain the following table, with just one token (word) per row.\n\n```{r sf_token_tbl, echo=TRUE}\nsf_token_tbl <- sf_line_tbl |> \n  tidytext::unnest_tokens(\n    input  = \"line\", \n    output = \"word\"\n  )\nsf_token_tbl\n```\n\nThe next step is to remove so-called stop-words, that is, articles (\"a\", \"the\", ...), connectors (\"and\", \"or\", ...) and other words that provide structure to a sentence but otherwise carry little information.  The `tidytext` package contains a data frame, `stop_words`, of such words, which enables us to remove them from the above table of tokens.\n\n```{r sf_tokens_xsw, echo=TRUE}\nsf_tokens_xsw <- sf_token_tbl |> \n  anti_join(\n    y  = tidytext::stop_words, \n    by = \"word\"\n  )\nsf_tokens_xsw\n```\n\n## Larger Text Examples\n\nWe'll use larger bodies of text via the following R packages.\n\n### Jane Austen's novels\n\n  - Package `janeaustenr`: Jane Austen (1775-1817) completed 6 novels, which the function `austen_books()` returns as a data frame with 2 columns: the `text` of the novels divided into strings (each approximating a line of printed text), and `book`, which gives the titles of the novels (in order of publication) as a factor.\n\nHere are the number of strings per book.\n\n```{r ja_strings_per_book}\nja_strings_per_book <- austen_books() |> \n  summarise(\n    .by = book, \n    n_strings = n()\n  )\nja_strings_per_book\n```\n\nHere are the ten words used most frequently across these novels.\n\n```{r ja_plus_chapters}\n# new columns per book: line number, chapter\nja_plus_chapters <- austen_books() |> \n  mutate(\n    .by        = book, \n    linenumber = row_number(),\n    chapter    = cumsum(\n      str_detect(\n        text, \n        regex(\n          \"^chapter [\\\\divxlc]\",\n          ignore_case = TRUE)\n      ))\n  )\n```\n\n```{r ja_words_raw}\n# break each line of text into several rows of words\nja_words_raw <- ja_plus_chapters |> \n  unnest_tokens(\n    input  = text, \n    output = word\n  )\n```\n\n```{r ja_words_xsw}\n# remove stop-words\nja_words_xsw <- ja_words_raw |> \n  anti_join(\n    y  = tidytext::stop_words, \n    by = \"word\")\n```\n\n```{r ja_word_ct}\n# count the number of occurrences of each word\n# list largest counts first\nja_word_ct <- ja_words_xsw |> \n  dplyr::count(word, sort = TRUE)\n```\n\n```{r ja_word_ct__kable}\nja_word_ct |> \n  dplyr::slice_head(n = 10) |> \n  knitr::kable(\n  caption = \"Jane Austen: 10 most frequently used words\", \n  col.names = c(\"word\", \"count\")\n)\n```\n\n### The Gutenberg Project\n  \n  - Package `gutenbergr`: Enables the user to download and process public domain works in the [Project Gutenberg](https://www.gutenberg.org/) collection.\n\nThe collection boasts over 75000 free electronic books.  The data frame `gutenberg_subjects` uses the Library of Congress Classifications (`lcc`) and Library of Congress Subject Headings (`lcsh`) to categorize topics included in the collection.  The package offers this and other such metadata to facilitate searching for desired works.\n\nAs a contrast with Jane Austen, here are some well-known science fiction novels of H.G. Wells (1866-1946).\n\n```{r hgwells_books}\nhgwells_books <- tibble::tribble(\n  ~id, ~title,\n    35L, \"The Time Machine\",\n    36L, \"The War of the Worlds\",\n  5230L, \"The Invisible Man\",\n   159L, \"The Island of Doctor Moreau\"\n)\nhgwells_books\n```\n\nAmong these novels, here are the most frequently used words.\n\n```{r hgwells_lines}\n# load file as tibble by one of these methods\nuncl_download <- FALSE\nload_rda      <- TRUE\n\nif (uncl_download) {\n  hgwells_lines <- gutenberg_download(\n    gutenberg_id = hgwells_books$ id)\n} else {\n  if (load_rda) {\n    load(here(\"data\", \"rda\", \"hgwells.rda\"))\n    hgwells_lines <- hgwells\n    rm(hgwells)\n  }\n}\n```\n\n```{r hgwells_words}\n# break each line into rows, one word per row\nhgwells_words <- hgwells_lines |> \n  unnest_tokens(\n    input  = text, \n    output = word\n  ) |> \n  # remove stop-words\n  anti_join(\n    y  = tidytext::stop_words, \n    by = \"word\")\n```\n\n```{r hgwells_words__write}\n# save as text file just once\nsave_file <- FALSE\nif (save_file) {\n  hgwells_words |> write_tsv(\n    here(\"data\", \"retain\", \"hgwells_words.txt\")\n  )\n}\n```\n\n```{r hgwells_word_ct}\nhgwells_word_ct <- hgwells_words |> \n  dplyr::count(word, sort = TRUE)\n```\n\n```{r hgwells_word_ct__kable}\nhgwells_word_ct |> \n  dplyr::slice_head(n = 10) |> \n  knitr::kable(\n  caption = \"H.G. Wells: 10 most frequently used words\", \n  col.names = c(\"word\", \"count\")\n)\n```\n\n## Class Exercise\n\nTeam up with a classmate and devise a way to compare word frequencies in the novels of Jane Austen and H.G. Wells, respectively.  Share with the class your comparison of just the top 10 words used by each author.  Propose a method for comparing all the words used by each author.  Take 20 minutes to prepare to report to the class.\n\n## TF-IDF\n\nCan the number of times each word appears in a document be used to indicate what the document is about?  On the one hand, the number of occurrences of a word in a document might be an indication of the importance of the word within the document.  On the other hand, words that commonly occur in most documents are unlikely to distinguish the key ideas in a single selected document.\n\nWe've already introduced the removal of stop-words as a means of separating the wheat from the chaff.  Another approach, called _tf-idf_, is to multiply a term's relative frequency (tf) in a selected document by its _inverse document frequency_ (idf) with respect to a collection or _corpus_ of documents.  That is, the relative frequency of a term $t$ in a specified document $d_0$ is the number of occurrences $\\mathcal{n}(t, d_0)$ of term $t$ in document $d_0$ divided by the number of occurrences of all terms in document $d_0$.\n\n$$\n\\begin{align}\n  tf(t, d_0) &= \\frac{\\mathcal{n}(t, d_0)}{\\sum_{t^\\prime \\in d_0}\\mathcal{n}(t^\\prime, d_0)}\n\\end{align}\n$$\n\nHere is one of several alternative definitions of idf.\n\n$$\n\\begin{align}\n  idf(\\text{term}) &= \\log_e {\\left(\\frac{n_{\\text{documents}}}{n_{\\text{documents containing term}}}\\right)}\n\\end{align}\n$$\n\nOr more formally, \n\n$$\n\\begin{align}\n  idf(t, \\mathcal{D}) &= \\log_e \\left( \\frac{| \\mathcal{D} |}{| \\mathcal{D}_t |} \\right) \\\\ \n  \\\\ \n  & t = \\text{term} \\\\ \n  & \\mathcal{D} = \\text{corpus of documents } \\\\\n  & \\mathcal{D}_t = \\{ d \\in \\mathcal{D} : t \\in d  \\}\n\\end{align}\n$$\n\nExample: let $\\mathcal{D}$ denote the set of Jane Austen's 6 novels, and let each novel take its turn as the document of interest.  Using tf-idf the most distinctive word per book is as follows.\n\n```{r ja_book_wd_ct}\n# count (book, word) occurrences\n# ignoring stop-words\nja_book_wd_ct <- ja_words_xsw |> \n  dplyr::count(book, word)\n```\n\n```{r ja_wd_in_books}\n# for each word, count books in which it appears\nja_wd_in_books <- ja_book_wd_ct |> \n  mutate(in_book = 1) |> \n  summarise(\n    .by = word, \n    n_books = sum(in_book, na.rm = TRUE)\n  )\n```\n\n```{r ja_book_all_ct}\n# for each book, sum (book, word) occurrences across words\nja_book_all_ct <- ja_book_wd_ct |> \n  summarise(\n    .by = book, \n    n   = sum(n, na.rm = TRUE)\n  )\n```\n\n```{r ja_tf_per_book}\n# relative frequency of each word per book\nja_tf_per_book <- ja_book_wd_ct |> \n  # n_all: number of all word instances per book\n  left_join(\n    by = \"book\", \n    y  = ja_book_all_ct |> rename(n_all = n)\n  ) |> \n  mutate(tf = n / n_all)\n```\n\n```{r ja_tf_idf}\n# use max tf-idf to find the most distinctive word per book\nja_tf_idf <- ja_tf_per_book |> \n  # n_books: number of books in which word appears\n  left_join(\n    by = \"word\", \n    y  = ja_wd_in_books\n  ) |> \n  mutate(\n    idf    = log(6 / n_books), \n    tf_idf = tf * idf\n  ) |> \n  arrange(book, desc(tf_idf))\n```\n\n```{r ja_max_wd_per_book}\nja_max_wd_per_book <- ja_tf_idf |> \n  group_by(book) |> \n  filter(tf_idf == max(tf_idf, na.rm = TRUE))\n```\n\n```{r ja_max_wd_per_book__kable}\nja_max_wd_per_book |> \n  knitr::kable(\n    caption = \"Max tf-idf word per book\", \n    digits = 2\n  )\n```\n\n\n## Document-Term Matices\n\n\n## Topic Models\n\n\n\n## Team Exercises\n\n  1.  XXX\n\n  1.  YYY\n\n## Resources\n\n[Text Mining with R: A Tidy Approach](https://www.tidytextmining.com/) by Silge and Robinson\n\n[tf–idf - Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(\n  echo    = FALSE, \n  error   = FALSE, \n  message = FALSE, \n  warning = FALSE\n)\n```\n\n```{r libraries}\nlibrary(assertthat)\nlibrary(GGally)\nlibrary(gutenbergr)\nlibrary(here)\nlibrary(ISLR2)\nlibrary(janeaustenr)\nlibrary(latex2exp)\nlibrary(tidytext)\nlibrary(tidyverse)\nlibrary(tinytex)\nlibrary(tokenizers)\nlibrary(topicmodels)\nlibrary(tufte)\n\n```\n\n```{r local_source}\n# source(here(\"code\", \"rmse_per_grp.R\"))\n# source(here(\"code\", \"xtabs_to_jaccard.R\"))\n```\n\n------------------------------------------------------------------------\n\n## Introduction\n\nThis session highlights some basic ideas and methods that underpin a rapidly advancing field.  We follow the online book by Silge and Robinson cited below and use their R package `tidytext`.  The authors emphasize the \"tidy\" formatting of data (i.e., as key-value pairs) along with a set of R packages sharing this approach, collectively called the R `tidyverse`.\n\n## Text Example\n\nToward the end of Shakespeare's play \"Macbeth\", the protagonist proclaims:\n\n```{r sound_fury}\nsound_fury <- c(\"Life's but a walking shadow, a poor player \",\n          \"That struts and frets his hour upon the stage, \",\n          \"And then is heard no more: it is a tale \", \n          \"Told by an idiot, full of sound and fury, \", \n          \"Signifying nothing.\")\n\nsound_fury\n```\n\n(Source: \"Macbeth\", Act V, Scene V, lines 24-28.)\n\nFor purposes of technical analysis we break these flowing lines into a table of words.  We begin as follows.\n\n```{r sf_line_tbl, echo=TRUE}\nsf_line_tbl <- tibble::tibble(\n  l_idx = 24:28, \n  line  = sound_fury\n)\nsf_line_tbl\n```\n\nThe table above merely identifies the original line number of each line.  The next step is to break each line into a sequence of \"tokens\", where a _token_ is a meaningful unit of text (such as a word) to be used as the unit of analysis.  (\"Tokenization\" is the process of splitting text into tokens.)  Applying `tidytext::unnest_tokens()` to the data table above, we obtain the following table, with just one token (word) per row.\n\n```{r sf_token_tbl, echo=TRUE}\nsf_token_tbl <- sf_line_tbl |> \n  tidytext::unnest_tokens(\n    input  = \"line\", \n    output = \"word\"\n  )\nsf_token_tbl\n```\n\nThe next step is to remove so-called stop-words, that is, articles (\"a\", \"the\", ...), connectors (\"and\", \"or\", ...) and other words that provide structure to a sentence but otherwise carry little information.  The `tidytext` package contains a data frame, `stop_words`, of such words, which enables us to remove them from the above table of tokens.\n\n```{r sf_tokens_xsw, echo=TRUE}\nsf_tokens_xsw <- sf_token_tbl |> \n  anti_join(\n    y  = tidytext::stop_words, \n    by = \"word\"\n  )\nsf_tokens_xsw\n```\n\n## Larger Text Examples\n\nWe'll use larger bodies of text via the following R packages.\n\n### Jane Austen's novels\n\n  - Package `janeaustenr`: Jane Austen (1775-1817) completed 6 novels, which the function `austen_books()` returns as a data frame with 2 columns: the `text` of the novels divided into strings (each approximating a line of printed text), and `book`, which gives the titles of the novels (in order of publication) as a factor.\n\nHere are the number of strings per book.\n\n```{r ja_strings_per_book}\nja_strings_per_book <- austen_books() |> \n  summarise(\n    .by = book, \n    n_strings = n()\n  )\nja_strings_per_book\n```\n\nHere are the ten words used most frequently across these novels.\n\n```{r ja_plus_chapters}\n# new columns per book: line number, chapter\nja_plus_chapters <- austen_books() |> \n  mutate(\n    .by        = book, \n    linenumber = row_number(),\n    chapter    = cumsum(\n      str_detect(\n        text, \n        regex(\n          \"^chapter [\\\\divxlc]\",\n          ignore_case = TRUE)\n      ))\n  )\n```\n\n```{r ja_words_raw}\n# break each line of text into several rows of words\nja_words_raw <- ja_plus_chapters |> \n  unnest_tokens(\n    input  = text, \n    output = word\n  )\n```\n\n```{r ja_words_xsw}\n# remove stop-words\nja_words_xsw <- ja_words_raw |> \n  anti_join(\n    y  = tidytext::stop_words, \n    by = \"word\")\n```\n\n```{r ja_word_ct}\n# count the number of occurrences of each word\n# list largest counts first\nja_word_ct <- ja_words_xsw |> \n  dplyr::count(word, sort = TRUE)\n```\n\n```{r ja_word_ct__kable}\nja_word_ct |> \n  dplyr::slice_head(n = 10) |> \n  knitr::kable(\n  caption = \"Jane Austen: 10 most frequently used words\", \n  col.names = c(\"word\", \"count\")\n)\n```\n\n### The Gutenberg Project\n  \n  - Package `gutenbergr`: Enables the user to download and process public domain works in the [Project Gutenberg](https://www.gutenberg.org/) collection.\n\nThe collection boasts over 75000 free electronic books.  The data frame `gutenberg_subjects` uses the Library of Congress Classifications (`lcc`) and Library of Congress Subject Headings (`lcsh`) to categorize topics included in the collection.  The package offers this and other such metadata to facilitate searching for desired works.\n\nAs a contrast with Jane Austen, here are some well-known science fiction novels of H.G. Wells (1866-1946).\n\n```{r hgwells_books}\nhgwells_books <- tibble::tribble(\n  ~id, ~title,\n    35L, \"The Time Machine\",\n    36L, \"The War of the Worlds\",\n  5230L, \"The Invisible Man\",\n   159L, \"The Island of Doctor Moreau\"\n)\nhgwells_books\n```\n\nAmong these novels, here are the most frequently used words.\n\n```{r hgwells_lines}\n# load file as tibble by one of these methods\nuncl_download <- FALSE\nload_rda      <- TRUE\n\nif (uncl_download) {\n  hgwells_lines <- gutenberg_download(\n    gutenberg_id = hgwells_books$ id)\n} else {\n  if (load_rda) {\n    load(here(\"data\", \"rda\", \"hgwells.rda\"))\n    hgwells_lines <- hgwells\n    rm(hgwells)\n  }\n}\n```\n\n```{r hgwells_words}\n# break each line into rows, one word per row\nhgwells_words <- hgwells_lines |> \n  unnest_tokens(\n    input  = text, \n    output = word\n  ) |> \n  # remove stop-words\n  anti_join(\n    y  = tidytext::stop_words, \n    by = \"word\")\n```\n\n```{r hgwells_words__write}\n# save as text file just once\nsave_file <- FALSE\nif (save_file) {\n  hgwells_words |> write_tsv(\n    here(\"data\", \"retain\", \"hgwells_words.txt\")\n  )\n}\n```\n\n```{r hgwells_word_ct}\nhgwells_word_ct <- hgwells_words |> \n  dplyr::count(word, sort = TRUE)\n```\n\n```{r hgwells_word_ct__kable}\nhgwells_word_ct |> \n  dplyr::slice_head(n = 10) |> \n  knitr::kable(\n  caption = \"H.G. Wells: 10 most frequently used words\", \n  col.names = c(\"word\", \"count\")\n)\n```\n\n## Class Exercise\n\nTeam up with a classmate and devise a way to compare word frequencies in the novels of Jane Austen and H.G. Wells, respectively.  Share with the class your comparison of just the top 10 words used by each author.  Propose a method for comparing all the words used by each author.  Take 20 minutes to prepare to report to the class.\n\n## TF-IDF\n\nCan the number of times each word appears in a document be used to indicate what the document is about?  On the one hand, the number of occurrences of a word in a document might be an indication of the importance of the word within the document.  On the other hand, words that commonly occur in most documents are unlikely to distinguish the key ideas in a single selected document.\n\nWe've already introduced the removal of stop-words as a means of separating the wheat from the chaff.  Another approach, called _tf-idf_, is to multiply a term's relative frequency (tf) in a selected document by its _inverse document frequency_ (idf) with respect to a collection or _corpus_ of documents.  That is, the relative frequency of a term $t$ in a specified document $d_0$ is the number of occurrences $\\mathcal{n}(t, d_0)$ of term $t$ in document $d_0$ divided by the number of occurrences of all terms in document $d_0$.\n\n$$\n\\begin{align}\n  tf(t, d_0) &= \\frac{\\mathcal{n}(t, d_0)}{\\sum_{t^\\prime \\in d_0}\\mathcal{n}(t^\\prime, d_0)}\n\\end{align}\n$$\n\nHere is one of several alternative definitions of idf.\n\n$$\n\\begin{align}\n  idf(\\text{term}) &= \\log_e {\\left(\\frac{n_{\\text{documents}}}{n_{\\text{documents containing term}}}\\right)}\n\\end{align}\n$$\n\nOr more formally, \n\n$$\n\\begin{align}\n  idf(t, \\mathcal{D}) &= \\log_e \\left( \\frac{| \\mathcal{D} |}{| \\mathcal{D}_t |} \\right) \\\\ \n  \\\\ \n  & t = \\text{term} \\\\ \n  & \\mathcal{D} = \\text{corpus of documents } \\\\\n  & \\mathcal{D}_t = \\{ d \\in \\mathcal{D} : t \\in d  \\}\n\\end{align}\n$$\n\nExample: let $\\mathcal{D}$ denote the set of Jane Austen's 6 novels, and let each novel take its turn as the document of interest.  Using tf-idf the most distinctive word per book is as follows.\n\n```{r ja_book_wd_ct}\n# count (book, word) occurrences\n# ignoring stop-words\nja_book_wd_ct <- ja_words_xsw |> \n  dplyr::count(book, word)\n```\n\n```{r ja_wd_in_books}\n# for each word, count books in which it appears\nja_wd_in_books <- ja_book_wd_ct |> \n  mutate(in_book = 1) |> \n  summarise(\n    .by = word, \n    n_books = sum(in_book, na.rm = TRUE)\n  )\n```\n\n```{r ja_book_all_ct}\n# for each book, sum (book, word) occurrences across words\nja_book_all_ct <- ja_book_wd_ct |> \n  summarise(\n    .by = book, \n    n   = sum(n, na.rm = TRUE)\n  )\n```\n\n```{r ja_tf_per_book}\n# relative frequency of each word per book\nja_tf_per_book <- ja_book_wd_ct |> \n  # n_all: number of all word instances per book\n  left_join(\n    by = \"book\", \n    y  = ja_book_all_ct |> rename(n_all = n)\n  ) |> \n  mutate(tf = n / n_all)\n```\n\n```{r ja_tf_idf}\n# use max tf-idf to find the most distinctive word per book\nja_tf_idf <- ja_tf_per_book |> \n  # n_books: number of books in which word appears\n  left_join(\n    by = \"word\", \n    y  = ja_wd_in_books\n  ) |> \n  mutate(\n    idf    = log(6 / n_books), \n    tf_idf = tf * idf\n  ) |> \n  arrange(book, desc(tf_idf))\n```\n\n```{r ja_max_wd_per_book}\nja_max_wd_per_book <- ja_tf_idf |> \n  group_by(book) |> \n  filter(tf_idf == max(tf_idf, na.rm = TRUE))\n```\n\n```{r ja_max_wd_per_book__kable}\nja_max_wd_per_book |> \n  knitr::kable(\n    caption = \"Max tf-idf word per book\", \n    digits = 2\n  )\n```\n\n\n## Document-Term Matices\n\n\n## Topic Models\n\n\n\n## Team Exercises\n\n  1.  XXX\n\n  1.  YYY\n\n## Resources\n\n[Text Mining with R: A Tidy Approach](https://www.tidytextmining.com/) by Silge and Robinson\n\n[tf–idf - Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":{"html_document":{"toc":true,"df_print":"paged","mathjax":"default"},"word_document":{"toc":true,"df_print":"tibble"},"pdf_document":{"toc":true,"df_print":"tibble"}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"s_2b_4350_2025-01-07_1900.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.57","editor":"visual","title":"Text Analysis","subtitle":"Part 1, session 2b of Data Mining Intro","author":[{"name":"Send comments to: Tony T (adthral)"}],"date":"`r format(Sys.time(), '%Y-%m-%d %H:%M', usetz = TRUE)`","abstract":"Introduce basic ideas and methods of text analysis."},"extensions":{"book":{"multiFile":true}}}},"projectFormats":[]}