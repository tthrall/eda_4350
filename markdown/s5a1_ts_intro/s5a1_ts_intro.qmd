---
title: "Time Series Data Analysis"
subtitle: "An Overview"
author:
  - name: "Send comments to: Tony T (tthrall)"
date: last-modified
date-format: HH:mm ddd D-MMM-YYYY
output:
  html_document:
    toc: true
    toc-depth: 2
    toc-location: body
    df_print: paged
    mathjax: default
  word_document:
    toc: true
    df_print: tibble
  pdf_document:
    toc: true
    df_print: tibble
abstract:
  "Introduce data examples in which successive observations are statistically dependent.  Discuss corresponding data analysis methods.  <br><br>"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo    = FALSE,
  error   = FALSE,
  message = FALSE,
  warning = FALSE
)
```

```{r cran_libraries}
library(assertthat)
library(astsa)
library(here)
library(knitr)
library(latex2exp)
library(tidyverse)
library(tinytex)
library(tsibble)
library(tsibbledata)
library(xts)
```

```{r local_libraries}
# library(ugrid)
```

```{r local_source}
# gen_ds_tbl
# compile a tibble that identifies data sets
source(here("code", "gen_ds_tbl.R"))

# get_ref_materials
# encapsulate reference materials as separate modules
source(here("code", "get_ref_materials.R"))
```

```{r plotting_params}
# grid-points in (-m pi, m pi), m = m_periods
# x_vec <- u_vec * (m_periods * pi)
```

```{r astsa_data_set_tbl}
astsa_data_set_tbl <- get_all_ds_per_pkg(pkgs = "astsa")

# write to file only as needed
save_to_file <- FALSE
if (save_to_file) {
  # TSV
  astsa_data_set_tbl |>
    readr::write_tsv(here(
	  "data", "retain", "astsa_data_set_tbl.txt"
	))
  # RDS
  astsa_data_set_tbl |>
    readr::write_rds(here(
	  "data", "rds", "astsa_data_set_tbl.rds"
	))
}
```

## Introduction

This technical note gives examples of data in which successive observations are statistically dependent and are typically indexed by time. Time series data sampled at regular intervals (daily stock prices, for example) are the most common case, followed by point process data representing the occurrence of events (earthquakes, for example) at random times.

Statistical models of such data include parametric models expressed in the time domain and non-parametric models expressed in the Fourier frequency domain (number of cycles per unit of time).

This note also comments on the detection of statistical dependence among successive observations and the modification of statistical tests and estimators for such data.

## Natural Science Examples

### Sunspots: Monthly Counts, 1749 - Present

#### Description

The figure below shows `sunspot.month`, the number of sunspots per month in `R` package `datasets`.  Source: Solar Influences Data Analysis Center (SIDC), Royal Observatory of Belgium.

```{r g_sunspots}
g_sunspots <- astsa::tsplot(
  x = datasets::sunspot.month, 
  ylab = "sunspot count", 
  col = 4)
```

#### Context: Questions and Objectives

As described in [Recalibration of the Sunspot-Number: Status Report | Solar Physics](https://link.springer.com/article/10.1007/s11207-023-02136-3), the record of sunspot numbers links past and present solar behavior, and is the primary input for reconstructions of total solar irradiance (TSI) for years before 1978.

### Old Faithful eruptions

#### Description

The figure below represents eruptions of the "Old Faithful" geyser in Yellowstone National Park, Wyoming from August 1 to August 15, 1985.[^faithful_pkgs]  The `delay` variable denotes the number of minutes since the previous eruption and the `duration` variable denotes the duration of the eruption, again in minutes.

[^faithful_pkgs]: There are two prominent `R` packages representing the Old Faithful measurements during August, 1985. The `MASS::geyser` data set of 299 observations includes nocturnal measurements whose duration was coded as 2, 3 or 4 minutes, having originally been described as ‘short’, ‘medium’ or ‘long’. The `datasets::faithful` data set of 272 measurements, shown in the figure, excludes 27 of these nocturnal measurements.

The data represent a _point process_, where each observation records the time of occurrence of a certain type of event, and may include other information about the occurrence.  Here the type of event is an eruption of the Old Faitful geyser.  In addition to the time of the eruption we have the duration of the eruption.

```{r faithful_tbl}
faithful_tbl <- datasets::faithful |> 
  tibble::as_tibble() |> 
  dplyr::rename(
    duration = eruptions, 
    delay    = waiting
  ) |> 
  dplyr::select(delay, duration)
```

```{r g_faithful_tbl}
g_faithful_tbl <- faithful_tbl |> 
  ggplot(mapping = aes(
    x = delay, y = duration
  )) + 
  geom_point() + 
  labs(title = "Old Faithful eruptions: delay and duration")
g_faithful_tbl
```

#### Context: Questions and Objectives

The figure shows two clusters of data points.  Old Faithful eruptions are conjectured to occur in 2 distinct temporal patterns due to the presence of an upper and lower chamber beneath the vertical column (tube) that forms the geyser.

In this example, we have the goal of scientific understanding of a natural phenomenon, supported by statistical modeling.

### Climate Change

```{r climate_ds_tbl}
# names of relevant data sets from package astsa::
climate_ds_names <- c(
  "cardox", "ENSO", "gtemp.month", "gtemp_both", 
  "gtemp_land", "gtemp_ocean", "soi"
)
climate_ds_tbl <- select_ds_per_pkg(
  pkgs = "astsa",
  datasets = climate_ds_names)
```

Here are some of the data sets related to climate change from the `R` package `astsa`.

```{r climate_ds_tbl__kable}
climate_ds_tbl |> knitr::kable(
  caption = "Climate: selected data sets"
)
```

#### Description

The figure below shows the time series `gtemp_land` and `gtemp_ocean`, annual temperature deviations (in ◦C) from averages for the period 1991-2020.[^gt_dev]  The temperatures are based on averages over the Earth’s land area and over the part of the ocean that is free of ice at all times (open ocean). The time period is from 1850 to 2023. Note that the trend is not linear, with periods of leveling off followed by sharp increases.

[^gt_dev]: The data source is [NOAA](https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/global/time-series/), who use the term "anomaly" rather than "deviation".  Further clarifications are pending.

```{r tmp_lob}
# join surface temperatures into multivariate ts
tmp_lo <- cbind(
  astsa::gtemp_land, 
  astsa::gtemp_ocean)
dimnames(tmp_lo) [[2]] <- c("land", "ocean")

tmp_lob <- 
  cbind(tmp_lo, astsa::gtemp_both)
dimnames(tmp_lob) [[2]] <- c("land", "ocean", "both")
```

```{r ref_lob_tbl}
# tmp_lob subset: 1991-2020
ref_lob_tbl <- tmp_lob |> 
  tibble::as_tibble() |> 
  dplyr::mutate(yr = 1850:2023) |> 
  dplyr::select(yr, land, ocean, both) |> 
  dplyr::filter(yr >= 1991, yr <= 2020)
```

```{r ref_lob_smy}
# check average deviation for reference period 1991-2020
land_smy_vec  <- ref_lob_tbl$ land  |> summary()
ocean_smy_vec <- ref_lob_tbl$ ocean |> summary()
both_smy_vec  <- ref_lob_tbl$ both  |> summary()

ref_lob_smy <- tibble::tibble(
  stat  = c("min", "q_1", "mid", "avg", "q_3", "max"), 
  land  = land_smy_vec, 
  ocean = ocean_smy_vec, 
  both  = both_smy_vec
)

# ref_lob_smy
# # A tibble: 6 × 4
#   stat  land     ocean     both     
#   <chr> <table>  <table>   <table>  
# 1 min   0.360000 0.2600000 0.3000000
# 2 q_1   0.815000 0.3700000 0.5175000
# 3 mid   1.120000 0.4350000 0.6750000
# 4 avg   1.193667 0.4776667 0.6993333
# 5 q_3   1.570000 0.5525000 0.8425000
# 6 max   2.500000 0.8300000 1.3500000
```

```{r gtemp__plot}
g_temp_lo <- astsa::tsplot(
  cbind(gtemp_land, gtemp_ocean), 
  spaghetti=TRUE, 
  col=astsa.col(c(4,2),.7), 
  pch=c(20,18), 
  type="o", 
  ylab="\u00B0C", 
  main="Global Surface Temperature Deviations", 
  addLegend=TRUE, 
  location="topleft", 
  legend=c("Land Surface","Sea Surface")
)
```

#### Context: Questions and Objectives

The upward trend in the two temperature series during the latter part of the 20th century has been used as an argument for the climate change hypothesis.  Further data and information would be needed, of course, to estimate the contributions of natural and anthropogenic sources to the observed rise in temperature.

###  El Niño and Fish Population

#### Description

The next figure shows the Southern Oscillation Index (SOI) and associated Recruitment (an index of the number of viable new fish).  Both series consist of 453 monthly values ranging over the years 1950–1987.

The two time series show two types of oscillation: an annual cycle (warm in the summer, cool in the winter), and a slower cycle that seems to repeat about every 4 years.

```{r soi__plot}
par(mfrow=2:1)
g_soi <- astsa::tsplot(soi, ylab="", main="Southern Oscillation Index", col=4)

text(1970, .91, "COOL", col=5, font=4)
text(1970, -.91, "WARM", col=6, font=4)

g_rec <- astsa::tsplot(rec, ylab="", main="Recruitment", col=4)
```

#### Context: Questions and Objectives

The processes that drive the periodicity of the two time series is of scientific interest.  Frequency decomposition of the time series may help to identify those underlying processes.

### Predator–Prey Interactions

#### Description

One of the classic studies of predator–prey interactions is based on the record of lynx and snowshoe hare pelts purchased by the Hudson’s Bay Company of Canada from 1845 to 1935.  Assuming pelt purchases are proportional to animals in the wild, the data are an indirect measure of predation.

These predator–prey interactions often lead to cyclical patterns of predator and prey abundance.  The units of the data shown in the next figure are thousands of pelts per year, for the years.

```{r pred_prey__plot}
g_hare_lynx <- tsplot(
  cbind(Hare, Lynx), 
  col=c(2,4), 
  type="o", 
  pch=c(0,2), 
  ylab="Number", 
  spaghetti=TRUE, 
  addLegend=TRUE)

mtext("(\u00D7 1000)", side=2, adj=1, line=1.5, cex=.8)
```

#### Context: Questions and Objectives

The scientific understanding of predator-prey interactions, starting with the Lotka-Volterra model (1910-1926), marked the beginnings of mathematical biology, and has been extended to the analysis of economic competition.

## Business and Economic Examples

### JJ Quarterly Earnings

#### Description

The figures below are Johnson & Johnson quarterly earnings per share in US dollars from 1960 through 1980.  The second figure shows the same data on a $\log_e$ scale.  Superimposed on the upward trend is an annual pattern, including a sharp rise to first quarter earnings from those of the previous quarter.

```{r jj__plot}
par(mfrow=2:1)

g_jj <- astsa::tsplot(
  jj, 
  col=4, 
  ylab="USD", 
  type="o", 
  main="Johnson & Johnson Quarterly Earnings per Share")

g_jj_log <- astsa::tsplot(
  jj, col=4, ylab="USD", type="o", log="y")
```

#### Context: Questions and Objectives

Developing a statistical model of the time series can be regarded as a first step toward an economic understanding.  With that understanding, various interested parties can set company performance goals, make investment decisions, or use this company as an example in a larger study.

###  Dow Jones Industrial Average

#### Description

The next figure shows the trading day closings and returns (percent change)[^djia_return] of the Dow Jones Industrial Average (DJIA) from 2006 to 2016. It is easy to spot the financial crisis of 2008.

[^djia_return]: The return is here calculated as the $log_e$ applied to the current day's closing price divided by that of the preceding day.  The median value is about 6 basis points.

```{r djia__plot}
# log-ratio of successive closing values
djia_return <- 
  astsa::djia $Close |> log() |> diff()

par(mfrow=2:1)

plot(djia$Close, col=4, main="DJIA Close")

plot(djia_return, col=4, main="DJIA Returns")
```

#### Context: Questions and Objectives

The returns of the DJIA are typical of other assets. The mean function of the series appears to be stable with an average return of approximately zero.  Of equal interest are highly volatile (variable) periods. That variability is both a symptom and cause of market uncertainty.  A challenge in the analysis of financial data is to forecast the volatility of future returns.

## Signal Processing Examples

### fMRI Imaging

#### Description

The next figure shows fMRI data from various locations in the cortex, thalamus, and cerebellum; n = 128 points, one observation taken every 2 seconds. The square wave shows the stimulus signal (on or off).

The data are from a 1997 study that used fMRI to examine pain perception in humans. Here we focus on five subjects whose hands were periodically brushed. The stimulus (represented as a square wave in the figure) was applied for 32 seconds and then stopped for 32 seconds so that the signal period is 64 seconds. The sampling rate was one observation every 2 seconds for 256 seconds (n = 128).

The data are consecutive measures of blood oxygenation-level dependent (BOLD) signal intensity, which measures areas of activation in the brain. The series shown are from two locations each in the cortex, thalamus, and cerebellum and the values are averaged over subjects (these were evoked responses and all subjects were in phase).

```{r fmri__plot}
par(mfrow=c(3,1))

# fMRI response data
x = ts(fmri1[,4:9], start=0, freq=32)

# square-wave stimulus
u = ts(
  rep(c(rep(.6,16), rep(-.6,16)), 4), 
  start=0, 
  freq=32)

# area of the brain
# fMRI recorded in two locations per area
names = c(
  "Cortex (2 locations)",
  "Thalamus (2 locations)",
  "Cerebellum (2 locations)"
)

g_fmri <- list()
for (i in 1:3){
  j = 2*i-1
  g_fmri [[i]] <- astsa::tsplot(
    x[,j:(j+1)], 
    ylab="BOLD", xlab="", 
    main=names[i], col=5:6, 
    ylim=c(-.6,.6), lwd=2, xaxt="n", spaghetti=TRUE
  )
  
  axis(seq(0,256,64), side=1, at=0:4)
  
  lines(u, type="s", col=gray(.3))
}

mtext("seconds", side=1, line=1.75, cex=.9)
```

#### Context: Questions and Objectives

Note that the periodicities appear strongly in the motor cortex series and less so in the thalamus and cerebellum. This experiment has been designed to test whether these distinct areas of the brain respond differently to the stimulus.

### Speech Recording

#### Description

The figure below shows the `speech` data set from the `astsa` package, a recording of the utterance _aaahhh_.  Note the repetitive nature of the signal and the rather regular periodicities.  Also note the repetition of small wavelets.  The separation between wavelets is known as the _pitch period_ and represents the response of the vocal tract filter to a periodic sequence of pulses stimulated by the opening and closing of the glottis.

```{r speech__plot}
g_speech <- astsa::tsplot(speech, col=4)
arrows(658, 3850, 766, 3850, 
       code=3, angle=90, length=.05, col=6)
text(712, 4100, "pitch period", cex=.75)
```

#### Context: Questions and Objectives

Computer recognition of speech is an active area of research and development.  In the current case one might seek to transcribe the signal above into the text string "aaahhh".  One approach would be a frequency based decomposition (spectral analysis) of the signal yielding a signature of the utterance that could be matched to one or more entries in a library of such signatures.

### Earthquakes and Explosions

#### Description

The next pair of figures show recordings (40 per second) at a Scandinavian seismic station of an earthquake and of a mining explosion.

```{r eqexp__plot}
g_eqexp <- astsa::tsplot(
  cbind(EQ5,EXP6), 
  ylab=c("Earthquake", "Explosion"), 
  col=4
)
```

#### Context: Questions and Objectives

The general problem of interest is to distinguish between waveforms generated by earthquakes versus those generated by explosions.

## Mathematical Framework

Statistical applications are often based on one or more data frames in which each row represents an observation and each column represents a variable of interest.  Consider for example the predator-prey data previously shown.

```{r hl_pelts}
hl_pelts <- tsibbledata::pelt |> 
  dplyr::rename(yr = Year, hare = Hare, lynx = Lynx) |> 
  dplyr::mutate(across(
    .cols = c(hare, lynx), 
    .fns  = ~ .x/1000
  ))
```

```{r hl_pelts__print}
hl_pelts |> as_tibble() |> print(n = 5)
```

The distinction of time series analysis is that observations are indexed by time, and are not assumed to be statistically independent.  In time series analysis, we typically consider the data to be a realization of a random process of the following form.

$$
\begin{align}
  X_\bullet (t) = (X_1 (t), \ldots, X_d (t))
\end{align}
$$

In our example the number $d$ of data columns is two (`hare`, `lynx`), the unit of time is one year,, and the sampling frequency is once per year.  The random process is idealized to span all time $(t \in \mathbb{Z})$, but the data of course span some finite period.

$$
\begin{align}
  t &= t_0 + u & \text{ with } u \in \{0, 1, \ldots, T-1 \}
\end{align}
$$

The expected value of the random process may be modeled by various functions of time: a constant, a linear trend, a seasonal component (periodic function), etc.

$$
\begin{align}
  m_\bullet (t) &= E \{ X_\bullet (t) \}
\end{align}
$$

Subtracting off this mean function, the remaining residual random process, $X_\bullet (t) - m_\bullet (t)$ , is often assumed to be __second-order stationary__.  That is, if we shift $X_\bullet (\cdot)$ by any number of time units $s$ to obtain a new proces $Y_\bullet (\cdot)$, we assume that the respective covariance structures of $X_\bullet (\cdot)$ and $Y_\bullet (\cdot)$ are the same.

$$
\begin{align}
  Y_\bullet (t) &= \mathcal{B}^s \{ X_\bullet (\cdot) \} (t)  \\ 
  &= X_\bullet (t - s)
\end{align}
$$

Here $\mathcal{B}$ denotes the _back-shift_ operator that shifts time by one unit, so that $\mathcal{B}^s$ (that is, $s$ repeated applications of $\mathcal{B}$) shifts time by $s$ units.  Then second-order stationarity can be expressed as follows.

$$
\begin{align}
  Cov \{ X_a (t + u), X_b (t) \} 
  &= Cov \{ Y_a (t + u), Y_b (t) \} \\ 
  &= Cov \{ X_a (t + u - s), X_b (t - s) \} \\ 
  \\ 
  & \text{for all } s \in \mathbb{Z} \text{ and } a, b \in \{ 1, \ldots, d \}
\end{align}
$$

Setting $s = t$ we have 

$$
\begin{align}
  Cov \{ X_a (t + u), X_b (t) \} 
  &= Cov \{ X_a (u), X_b (0) \} 
\end{align}
$$
Consequently, second-order stationary enables one to define and estimate the following _auto-covariance_ function.

$$
\begin{align}
  \gamma_{\bullet, \bullet} (u) &= \left \{ \gamma_{a, b} (u) \right \}_{a, b = 1}^d \\ 
  \\ 
  \text{where} \\
  \gamma_{a, b} (u) &= Cov \{ X_a (t + u), X_b (t) \} \\
  &= Cov \{ X_a (u), X_b (0) \} 
\end{align}
$$

## Operations on Time Series

The data transformations used on independent observations are applicable to time series data.  For example, in the case of Johnson and Johnson quarterly earnings, we saw that the transformed time series, $Y(t) = \log_e (X(t))$, could be more closely approximated by a linear trend.

In addition to the data transformations used on independent observations, we often want to average time series data over time.

As an example, the figure below shows a 5-year moving average of the global temperature data previously shown.  This operation smooths out local fluctuations to show the overall trend more clearly.

```{r gt_lo}
gt_lo <- cbind(
  astsa::gtemp_land, astsa::gtemp_ocean)
names(gt_lo) <- c("land", "ocean")
```

```{r gt_lo_ma5}
gt_lo_ma5 <- gt_lo |> 
  stats::filter(filter = rep(1/5, 5))
names(gt_lo_ma5) <- c("land", "ocean")
```

```{r gt_lo_ma5__tsplot}
astsa::tsplot(
  gt_lo_ma5, 
  ncolm = 2, 
  spaghetti=TRUE, 
  col=astsa.col(c(4,2),.7), 
  pch=c(20,18), 
  type="o", 
  ylab="\u00B0C", 
  main="Temperature Deviations (5-year avg)", 
  addLegend=TRUE, 
  location="topleft", 
  legend=c("Land Surface","Sea Surface")
)
```

In this case the 5-year moving average operation can be expressed as follows.

$$
\begin{align}
  Y_\bullet (t) 
  &= \frac{1}{5} \sum_{u = -2}^2 X_\bullet (t - u) 
\end{align}
$$

where $X_\bullet (\cdot)$ is a two-component time series representing annual global averages of land and ocean temperatures.  This 5-year moving average is an example of a linear, time-invariant filter, having the following general form.

$$
\begin{align}
  Y_\bullet (t) 
  &= a_{\bullet, \bullet} (\cdot) \; * \; X_\bullet (\cdot)  \\ 
  &= \sum_u a_{\bullet, \bullet} (u) \; \times \; X_\bullet (t - u) 
\end{align}
$$

where $a_{\bullet, \bullet} (\cdot)$ is a sequence of $d \times d$ matrices and $*$ denotes discrete convolution.

For example, here's the 5-year moving average above expressed in this format.

$$
\begin{align}
  a_{\bullet, \bullet} (u) &= 
    \begin{cases}
      \frac{1}{5} I & \text{ for } |u| \le 2 \\ 
      0 & \text{ for } |u| > 2
    \end{cases}
\end{align}
$$

As noted above, the moving average operation can help to reveal and thus model the trend in the process, $m_\bullet (t)$.  Forming the residual series $X_\bullet (t) - m_\bullet (t)$ is called "de-trending".  If the trend is linear, an alternative is to form differences of the current observation minus its predecessor.  This is an application of the "differencing" operator $\mathcal{D} = \mathcal{I} - \mathcal{B}$.

$$
\begin{align}
  Y_\bullet (t) 
  &= X_\bullet (t)  - X_\bullet (t - 1) \\ 
  &= (\mathcal{I} - \mathcal{B}) \{ X_\bullet (\cdot) \} (t) \\ 
  &= \mathcal{D} \{ X_\bullet (\cdot) \} (t)
\end{align}
$$

In the DJIA stock index example, returns were defined as the log-ratio of successive closing values, calculated as the difference in successive values of the logarithm of the closing values.  Here's the differencing operator $\mathcal{D}$ in the filtering format.

$$
\begin{align}
  a_{\bullet, \bullet} (u) &= 
    \begin{cases}
      I  & \text{ for } u = 0 \\ 
      -I & \text{ for } u = 1 \\ 
      0  & \text{ otherwise }
    \end{cases}
\end{align}
$$

A moving average operation smooths the time series on which it operates.  That is, it allows low-frequency components to pass, while diminishing high-frequency components.  Therefore the moving average operation is categorized as a _low-pass_ filter.  The differencing operator can be categorized as a _high-pass_ filter.

In signal-processing applications a linear, time-invariant filter $a_{\bullet, \bullet} (\cdot)$ may be designed to extract certain types of signals that are contaminated by noise.

## Data Analysis Objectives & Methods

## Detecting Observational Dependence

## Closing Remarks

```{r symbol_tbl}
## Glossary of Math Symbols

symbol_tbl <- get_symbol_tbl()
```

```{r symbol_tbl__save}
# save file only when updated
save_to_file <- FALSE
if (save_to_file) {
  # RDS format
  symbol_tbl |> readr::write_rds(here::here(
    "data", "retain", "symbol_tbl.rds"
  ))

  # TSV format
  symbol_tbl |> readr::write_tsv(here::here(
    "data", "retain", "symbol_tbl.txt"
  ))
}
```

```{r symbol_tbl__kable}
# symbol_tbl |>
#   dplyr::select(symbol, dscr) |>
#   knitr::kable(
#     format = "html",
# 	escape = FALSE,
# 	caption = "Glossary of Mathematical Symbols (s)",
# 	col.names = c("s", "description")
#   )
```

## Resources

### Books

```{r books_tbl}
books_tbl <- get_books_tbl() |>
  dplyr::arrange(title)
```

```{r books_tbl__save}
# save file only when updated
save_to_file <- FALSE
if (save_to_file) {
  # RDS format
  books_tbl |> readr::write_rds(here::here(
    "data", "retain", "books_tbl.rds"
  ))

  # TSV format
  books_tbl |> readr::write_tsv(here::here(
    "data", "retain", "books_tbl.txt"
  ))
}
```

```{r books_tbl__kable}
books_tbl |>
  list_links(a_idx = 3L) |>
  knitr::kable(
    format    = "html",
    escape    = FALSE,
    col.names = ""
  )
```

### Articles

```{r articles_tbl}
articles_tbl <- get_articles_tbl() |>
  dplyr::arrange(title)
```

```{r articles_tbl__save}
# save file only when updated
save_to_file <- FALSE
if (save_to_file) {
  # RDS format
  articles_tbl |> readr::write_rds(here::here(
    "data", "retain", "articles_tbl.rds"
  ))

  # TSV format
  articles_tbl |> readr::write_tsv(here::here(
    "data", "retain", "articles_tbl.txt"
  ))
}
```

```{r articles_tbl__kable}
articles_tbl |>
  list_links() |>
  knitr::kable(
    format    = "html",
    escape    = FALSE,
    col.names = ""
  )
```
